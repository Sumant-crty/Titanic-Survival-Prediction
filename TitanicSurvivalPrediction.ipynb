import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# ==========================================
# рддрд░реАрдХрд╛ 1: рдбреЗрдЯрд╛ рд▓реЛрдбрд┐рдВрдЧ рдФрд░ рдХреНрд▓реАрдирд┐рдВрдЧ (Data Cleaning)
# ==========================================
def load_and_clean_data(file_path):
    # рдбреЗрдЯрд╛ рд▓реЛрдб рдХрд░реЗрдВ
    df = pd.read_csv(file_path)
    
    # 1. Missing Values рднрд░реЗрдВ
    df['Age'] = df['Age'].fillna(df['Age'].median())
    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])
    df['Fare'] = df['Fare'].fillna(df['Fare'].median())
    
    # 2. рдЕрдирд╛рд╡рд╢реНрдпрдХ рдХреЙрд▓рдореНрд╕ рд╣рдЯрд╛рдПрдВ
    df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
    
    # 3. рдлреАрдЪрд░ рдЗрдВрдЬреАрдирд┐рдпрд░рд┐рдВрдЧ (One-Hot Encoding)
    # Sex рдФрд░ Embarked рдХреЛ рдирдВрдмрд░реНрд╕ рдореЗрдВ рдмрджрд▓реЗрдВ
    df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)
    
    return df

# ==========================================
# рддрд░реАрдХрд╛ 2: рдореЙрдбрд▓ рдЯреНрд░реЗрдирд┐рдВрдЧ (Random Forest)
# ==========================================
# рдорд╛рди рд▓реАрдЬрд┐рдП рдЖрдкрдХреА рдлрд╛рдЗрд▓ рдХрд╛ рдирд╛рдо 'train.csv' рд╣реИ
data = load_and_clean_data('train.csv')

X = data.drop('Survived', axis=1)
y = data['Survived']

# рдбреЗрдЯрд╛ рдХреЛ рдмрд╛рдВрдЯреЗрдВ
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ==========================================
# рддрд░реАрдХрд╛ 3: рд╣рд╛рдЗрдкрд░рдкреИрд░рд╛рдореАрдЯрд░ рдЯреНрдпреВрдирд┐рдВрдЧ (GridSearchCV)
# ==========================================
print("--- Hypertuning starting... ---")

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [5, 10, None],
    'min_samples_split': [2, 5],
    'criterion': ['gini', 'entropy']
}

grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1)
grid_search.fit(X_train, y_train)

# рдмреЗрд╕реНрдЯ рдореЙрдбрд▓ рдЪреБрдиреЗрдВ
best_model = grid_search.best_estimator_

# ==========================================
# рдкрд░рд┐рдгрд╛рдо рдФрд░ рд╡рд┐рдЬрд╝реБрдЕрд▓рд╛рдЗрдЬрд╝реЗрд╢рди (Evaluation)
# ==========================================
y_pred = best_model.predict(X_test)

print(f"\n Best Parameters: {grid_search.best_params_}")
print(f"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%")

# 1. рдХрдиреНрдлреНрдпреВрдЬрди рдореИрдЯреНрд░рд┐рдХреНрд╕ рдкреНрд▓реЙрдЯ рдХрд░реЗрдВ
plt.figure(figsize=(6,4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Greens')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# 

# 2. рдлреАрдЪрд░ рдЗрдореНрдкреЛрд░реНрдЯреЗрдВрд╕ (Feature Importance)
features = pd.Series(best_model.feature_importances_, index=X.columns)
features.nlargest(10).plot(kind='barh')
plt.title('Feature Importance')
plt.show()

# 

print("\n--- Project completed! ---")
# ==========================================
# рдЕрдкрдирд╛ рдЦреБрдж рдХрд╛ рдЯреЗрд╕реНрдЯ (Predict your own survival)
# ==========================================

print("\n" + "="*30)
print("рдХреНрдпрд╛ рдЖрдк рдЯрд╛рдЗрдЯреИрдирд┐рдХ рдкрд░ рдмрдЪ рдкрд╛рддреЗ?")
print("="*30)

# рдЖрдкрд╕реЗ рдЬрд╛рдирдХрд╛рд░реА рдорд╛рдВрдЧрдирд╛
pclass = int(input("рдЖрдк рдХрд┐рд╕ рдХреНрд▓рд╛рд╕ рдореЗрдВ рд╕рдлрд░ рдХрд░рддреЗ? (1, 2, рдпрд╛ 3): "))
age = float(input("рдЖрдкрдХреА рдЙрдореНрд░ рдХреНрдпрд╛ рд╣реИ?: "))
sibsp = int(input("рдЖрдкрдХреЗ рд╕рд╛рде рдХрд┐рддрдиреЗ рднрд╛рдИ-рдмрд╣рди рдпрд╛ рдЬреАрд╡рдирд╕рд╛рдереА рд╣реИрдВ?: "))
parch = int(input("рдЖрдкрдХреЗ рд╕рд╛рде рдХрд┐рддрдиреЗ рдорд╛рддрд╛-рдкрд┐рддрд╛ рдпрд╛ рдмрдЪреНрдЪреЗ рд╣реИрдВ?: "))
fare = float(input("рдЯрд┐рдХрдЯ рдХрд╛ рдХрд┐рд░рд╛рдпрд╛ рдХрд┐рддрдирд╛ рджреЗрдВрдЧреЗ? (рдФрд╕рдд 10-50 рдХреЗ рдмреАрдЪ): "))
sex = input("рдЖрдкрдХрд╛ рд▓рд┐рдВрдЧ рдХреНрдпрд╛ рд╣реИ? (male/female): ").lower()
embarked = input("рдЖрдк рдХрд╣рд╛рдБ рд╕реЗ рд╕рд╡рд╛рд░ рд╣реЛрддреЗ? (S, C, рдпрд╛ Q): ").upper()

# рдбреЗрдЯрд╛ рдХреЛ рдореЙрдбрд▓ рдХреЗ рдлреЙрд░реНрдореЗрдЯ рдореЗрдВ рдмрджрд▓рдирд╛
my_data = pd.DataFrame({
    'Pclass': [pclass],
    'Age': [age],
    'SibSp': [sibsp],
    'Parch': [parch],
    'Fare': [fare],
    'Sex_male': [1 if sex == 'male' else 0],
    'Embarked_Q': [1 if embarked == 'Q' else 0],
    'Embarked_S': [1 if embarked == 'S' else 0]
})

# рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдХрд░рдирд╛
prediction = best_model.predict(my_data)
probability = best_model.predict_proba(my_data)[0][1]

if prediction[0] == 1:
    print(f"\nрдмрдзрд╛рдИ рд╣реЛ! рдЖрдкрдХреЗ рдмрдЪрдиреЗ рдХреА рд╕рдВрднрд╛рд╡рдирд╛ {probability*100:.2f}% рд╣реИред рдЖрдк рдмрдЪ рдЬрд╛рддреЗ! ЁЯОЙ")
else:
    print(f"\nрдЕреЮрд╕реЛрд╕! рдЖрдкрдХреЗ рдмрдЪрдиреЗ рдХреА рд╕рдВрднрд╛рд╡рдирд╛ рдХреЗрд╡рд▓ {probability*100:.2f}% рд╣реИред рдЯрд╛рдЗрдЯреИрдирд┐рдХ рдХреЗ рд╕рд╛рде рдбреВрдмрдиреЗ рдХрд╛ рдЦрддрд░рд╛ рд╣реИред ЁЯМК")
